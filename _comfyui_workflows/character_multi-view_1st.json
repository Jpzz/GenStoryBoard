{
  "1": {
    "inputs": {
      "box_v": 1.01,
      "octree_resolution": 384,
      "num_chunks": 32000,
      "mc_level": 0,
      "mc_algo": "mc",
      "enable_flash_vdm": true,
      "force_offload": true,
      "vae": [
        "4",
        1
      ],
      "latents": [
        "80",
        0
      ]
    },
    "class_type": "Hy3DVAEDecode",
    "_meta": {
      "title": "Hy3D VAE Decode"
    }
  },
  "2": {
    "inputs": {
      "mask": [
        "3",
        0
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "Convert Mask to Image"
    }
  },
  "3": {
    "inputs": {
      "value": 0.8,
      "width": 512,
      "height": 512
    },
    "class_type": "SolidMask",
    "_meta": {
      "title": "SolidMask"
    }
  },
  "4": {
    "inputs": {
      "model": "hy3dgen\\hunyuan3d-dit-v2-0-fp16.safetensors",
      "attention_mode": "sdpa",
      "cublas_ops": false
    },
    "class_type": "Hy3DModelLoader",
    "_meta": {
      "title": "Hy3DModelLoader"
    }
  },
  "6": {
    "inputs": {
      "pulid_file": "pulid_flux_v0.9.1.safetensors"
    },
    "class_type": "PulidFluxModelLoader",
    "_meta": {
      "title": "Load PuLID Flux Model"
    }
  },
  "7": {
    "inputs": {},
    "class_type": "PulidFluxEvaClipLoader",
    "_meta": {
      "title": "Load Eva Clip (PuLID Flux)"
    }
  },
  "8": {
    "inputs": {
      "model": "hunyuan3d-delight-v2-0"
    },
    "class_type": "DownloadAndLoadHy3DDelightModel",
    "_meta": {
      "title": "(Down)Load Hy3D DelightModel"
    }
  },
  "9": {
    "inputs": {
      "scheduler": "Euler A",
      "sigmas": "default",
      "pipeline": [
        "8",
        0
      ]
    },
    "class_type": "Hy3DDiffusersSchedulerConfig",
    "_meta": {
      "title": "Hy3D Diffusers Scheduler Config"
    }
  },
  "10": {
    "inputs": {
      "x": 0,
      "y": 0,
      "resize_source": false,
      "destination": [
        "2",
        0
      ],
      "source": [
        "16",
        0
      ],
      "mask": [
        "16",
        1
      ]
    },
    "class_type": "ImageCompositeMasked",
    "_meta": {
      "title": "ImageCompositeMasked"
    }
  },
  "13": {
    "inputs": {
      "width": 518,
      "height": 518,
      "interpolation": "lanczos",
      "method": "pad",
      "condition": "always",
      "multiple_of": 2,
      "image": [
        "81",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "🔧 Image Resize"
    }
  },
  "14": {
    "inputs": {
      "mode": "base",
      "use_jit": true
    },
    "class_type": "TransparentBGSession+",
    "_meta": {
      "title": "🔧 InSPyReNet TransparentBG"
    }
  },
  "16": {
    "inputs": {
      "rembg_session": [
        "14",
        0
      ],
      "image": [
        "13",
        0
      ]
    },
    "class_type": "ImageRemoveBackground+",
    "_meta": {
      "title": "🔧 Image Remove Background"
    }
  },
  "18": {
    "inputs": {
      "steps": 50,
      "width": 512,
      "height": 512,
      "cfg_image": 1,
      "seed": 0,
      "delight_pipe": [
        "8",
        0
      ],
      "image": [
        "16",
        0
      ],
      "scheduler": [
        "9",
        0
      ]
    },
    "class_type": "Hy3DDelightImage",
    "_meta": {
      "title": "Hy3DDelightImage"
    }
  },
  "22": {
    "inputs": {
      "trimesh": [
        "41",
        0
      ]
    },
    "class_type": "Hy3DMeshUVWrap",
    "_meta": {
      "title": "Hy3D Mesh UV Wrap"
    }
  },
  "23": {
    "inputs": {
      "model": "hunyuan3d-paint-v2-0"
    },
    "class_type": "DownloadAndLoadHy3DPaintModel",
    "_meta": {
      "title": "(Down)Load Hy3D PaintModel"
    }
  },
  "25": {
    "inputs": {
      "render_size": 1024,
      "texture_size": 2048,
      "normal_space": "world",
      "trimesh": [
        "22",
        0
      ],
      "camera_config": [
        "30",
        0
      ]
    },
    "class_type": "Hy3DRenderMultiView",
    "_meta": {
      "title": "Hy3D Render MultiView"
    }
  },
  "26": {
    "inputs": {
      "view_size": 512,
      "steps": 25,
      "seed": 1024,
      "denoise_strength": 1,
      "pipeline": [
        "23",
        0
      ],
      "ref_image": [
        "18",
        0
      ],
      "normal_maps": [
        "25",
        0
      ],
      "position_maps": [
        "25",
        1
      ],
      "camera_config": [
        "30",
        0
      ],
      "scheduler": [
        "28",
        0
      ]
    },
    "class_type": "Hy3DSampleMultiView",
    "_meta": {
      "title": "Hy3D Sample MultiView"
    }
  },
  "28": {
    "inputs": {
      "scheduler": "Euler A",
      "sigmas": "default",
      "pipeline": [
        "23",
        0
      ]
    },
    "class_type": "Hy3DDiffusersSchedulerConfig",
    "_meta": {
      "title": "Hy3D Diffusers Scheduler Config"
    }
  },
  "29": {
    "inputs": {
      "string": "0,30,60,120,150,210,240,300,330"
    },
    "class_type": "String Literal (Image Saver)",
    "_meta": {
      "title": "String Literal (Image Saver)"
    }
  },
  "30": {
    "inputs": {
      "camera_azimuths": [
        "29",
        0
      ],
      "camera_elevations": [
        "52",
        0
      ],
      "view_weights": "1, 0.1, 0.5, 0.1, 0.05, 0.05",
      "camera_distance": 1.45,
      "ortho_scale": 1.2
    },
    "class_type": "Hy3DCameraConfig",
    "_meta": {
      "title": "Hy3D Camera Config"
    }
  },
  "33": {
    "inputs": {
      "provider": "CUDA"
    },
    "class_type": "PulidFluxInsightFaceLoader",
    "_meta": {
      "title": "Load InsightFace (PuLID Flux)"
    }
  },
  "40": {
    "inputs": {
      "crop_padding_factor": 0.25,
      "cascade_xml": "lbpcascade_animeface.xml",
      "image": [
        "81",
        0
      ]
    },
    "class_type": "Image Crop Face",
    "_meta": {
      "title": "Image Crop Face"
    }
  },
  "41": {
    "inputs": {
      "remove_floaters": true,
      "remove_degenerate_faces": true,
      "reduce_faces": true,
      "max_facenum": 50149,
      "smooth_normals": false,
      "trimesh": [
        "1",
        0
      ]
    },
    "class_type": "Hy3DPostprocessMesh",
    "_meta": {
      "title": "Hy3D Postprocess Mesh"
    }
  },
  "42": {
    "inputs": {
      "ckpt_name": "flux\\flux1-dev-fp8.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "43": {
    "inputs": {
      "lora_stack": [
        "71",
        0
      ],
      "model": [
        "42",
        0
      ],
      "optional_clip": [
        "42",
        1
      ]
    },
    "class_type": "easy loraStackApply",
    "_meta": {
      "title": "Easy Apply LoraStack"
    }
  },
  "47": {
    "inputs": {
      "border_width": 0,
      "number_of_columns": 3,
      "max_cell_size": 512,
      "border_red": 0,
      "border_green": 0,
      "border_blue": 0,
      "images": [
        "26",
        0
      ]
    },
    "class_type": "Create Grid Image from Batch",
    "_meta": {
      "title": "Create Grid Image from Batch"
    }
  },
  "48": {
    "inputs": {
      "weight": 0.8000000000000002,
      "start_at": 0,
      "end_at": 0.9000000000000002,
      "model": [
        "43",
        0
      ],
      "pulid_flux": [
        "6",
        0
      ],
      "eva_clip": [
        "7",
        0
      ],
      "face_analysis": [
        "33",
        0
      ],
      "image": [
        "81",
        0
      ]
    },
    "class_type": "ApplyPulidFlux",
    "_meta": {
      "title": "Apply PuLID Flux"
    }
  },
  "50": {
    "inputs": {
      "model_name": "bbox/face_yolov8m.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "UltralyticsDetectorProvider"
    }
  },
  "52": {
    "inputs": {
      "string": "0,0,0,0,0,0,0,0,0"
    },
    "class_type": "String Literal (Image Saver)",
    "_meta": {
      "title": "String Literal (Image Saver)"
    }
  },
  "54": {
    "inputs": {
      "object_to_patch": "diffusion_model",
      "residual_diff_threshold": 0.12000000000000002,
      "start": 0,
      "end": 1,
      "max_consecutive_cache_hits": -1,
      "model": [
        "48",
        0
      ]
    },
    "class_type": "ApplyFBCacheOnModel",
    "_meta": {
      "title": "Apply First Block Cache"
    }
  },
  "55": {
    "inputs": {
      "model": "MiaoshouAI/Florence-2-base-PromptGen-v2.0",
      "precision": "fp16",
      "attention": "sdpa"
    },
    "class_type": "DownloadAndLoadFlorence2Model",
    "_meta": {
      "title": "DownloadAndLoadFlorence2Model"
    }
  },
  "56": {
    "inputs": {
      "inputcount": 3,
      "delimiter": ",",
      "return_list": false,
      "Update inputs": null,
      "string_1": [
        "78",
        0
      ],
      "string_2": [
        "104",
        0
      ],
      "string_3": [
        "79",
        0
      ]
    },
    "class_type": "JoinStringMulti",
    "_meta": {
      "title": "Join String Multi"
    }
  },
  "57": {
    "inputs": {
      "text_0": "a character sheet showing multiple views of a character in front of a gray background, best quality, not blurry, not nsfw, master piece, showing hands, not bad hands,A digital illustration shoot from a portrait camera angle about a close-up portrait of a young woman with long, wavy brown hair and large, expressive brown eyes. the image also shows a simple, light-colored background. on the middle of the image, a 20-year-old light-skinned woman appears to be smiling, looking at the viewer with a friendly expression. she has long, dark brown hair that falls down her back, and her eyes are large and expressive, with a slight blush on her cheeks. her hair is parted in the middle, and she has a small nose and full lips. the woman is wearing a simple white shirt and her hair style is long hair.  1girl, solo, long hair, simple background, brown hair, black hair, closed mouth, brown eyes, closed eyes, eyelashes, lips, portrait, nose, realistic  camera_angle: portrait, art_style: digital illustration, location: NA, background: plain, light gray background that does not distract from the subject. The image is high quality and well-composed with jpeg artifacts.,3d pixar character",
      "text": [
        "56",
        0
      ]
    },
    "class_type": "ShowText|pysssss",
    "_meta": {
      "title": "Show Text 🐍"
    }
  },
  "61": {
    "inputs": {
      "pixels": [
        "105",
        0
      ],
      "vae": [
        "42",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "65": {
    "inputs": {
      "control_net_name": "FLUX.1\\InstantX-FLUX1-Dev-Union\\diffusion_pytorch_model.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "68": {
    "inputs": {
      "seed": 1060061471795405,
      "steps": 35,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 0.8500000000000002,
      "model": [
        "54",
        0
      ],
      "positive": [
        "73",
        0
      ],
      "negative": [
        "73",
        1
      ],
      "latent_image": [
        "61",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler-01"
    }
  },
  "70": {
    "inputs": {
      "type": "canny/lineart/anime_lineart/mlsd",
      "control_net": [
        "65",
        0
      ]
    },
    "class_type": "SetUnionControlNetType",
    "_meta": {
      "title": "SetUnionControlNetType"
    }
  },
  "71": {
    "inputs": {
      "toggle": true,
      "mode": "simple",
      "num_loras": 1,
      "lora_1_name": "FLUX1.0\\Jixar_flux_v2.safetensors",
      "lora_1_strength": 1,
      "lora_1_model_strength": 1,
      "lora_1_clip_strength": 1,
      "lora_2_name": "None",
      "lora_2_strength": 1,
      "lora_2_model_strength": 1,
      "lora_2_clip_strength": 1,
      "lora_3_name": "None",
      "lora_3_strength": 1,
      "lora_3_model_strength": 1,
      "lora_3_clip_strength": 1,
      "lora_4_name": "None",
      "lora_4_strength": 1,
      "lora_4_model_strength": 1,
      "lora_4_clip_strength": 1,
      "lora_5_name": "None",
      "lora_5_strength": 1,
      "lora_5_model_strength": 1,
      "lora_5_clip_strength": 1,
      "lora_6_name": "None",
      "lora_6_strength": 1,
      "lora_6_model_strength": 1,
      "lora_6_clip_strength": 1,
      "lora_7_name": "None",
      "lora_7_strength": 1,
      "lora_7_model_strength": 1,
      "lora_7_clip_strength": 1,
      "lora_8_name": "None",
      "lora_8_strength": 1,
      "lora_8_model_strength": 1,
      "lora_8_clip_strength": 1,
      "lora_9_name": "None",
      "lora_9_strength": 1,
      "lora_9_model_strength": 1,
      "lora_9_clip_strength": 1,
      "lora_10_name": "None",
      "lora_10_strength": 1,
      "lora_10_model_strength": 1,
      "lora_10_clip_strength": 1
    },
    "class_type": "easy loraStack",
    "_meta": {
      "title": "EasyLoraStack"
    }
  },
  "73": {
    "inputs": {
      "strength": 0.6500000000000001,
      "start_percent": 0,
      "end_percent": 0.6000000000000001,
      "positive": [
        "90",
        0
      ],
      "negative": [
        "92",
        0
      ],
      "control_net": [
        "70",
        0
      ],
      "image": [
        "122",
        0
      ],
      "vae": [
        "42",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "74": {
    "inputs": {
      "images": [
        "75",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "75": {
    "inputs": {
      "samples": [
        "68",
        0
      ],
      "vae": [
        "42",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "77": {
    "inputs": {
      "text_input": "",
      "task": "prompt_gen_mixed_caption_plus",
      "fill_mask": true,
      "keep_model_loaded": false,
      "max_new_tokens": 1024,
      "num_beams": 3,
      "do_sample": true,
      "output_mask_select": "",
      "seed": 648031793686236,
      "image": [
        "40",
        0
      ],
      "florence2_model": [
        "55",
        0
      ]
    },
    "class_type": "Florence2Run",
    "_meta": {
      "title": "Florence2Run"
    }
  },
  "78": {
    "inputs": {
      "string": "a character sheet showing multiple views of a character in front of a gray background, best quality, not blurry, not nsfw, master piece, showing hands, not bad hands"
    },
    "class_type": "String Literal (Image Saver)",
    "_meta": {
      "title": "String Literal (Image Saver)"
    }
  },
  "79": {
    "inputs": {
      "string": "3d pixar character"
    },
    "class_type": "String Literal (Image Saver)",
    "_meta": {
      "title": "Style"
    }
  },
  "80": {
    "inputs": {
      "guidance_scale": 5.5,
      "steps": 40,
      "seed": 123,
      "scheduler": "FlowMatchEulerDiscreteScheduler",
      "force_offload": true,
      "pipeline": [
        "4",
        0
      ],
      "image": [
        "16",
        0
      ],
      "mask": [
        "16",
        1
      ]
    },
    "class_type": "Hy3DGenerateMesh",
    "_meta": {
      "title": "Hy3DGenerateMesh"
    }
  },
  "81": {
    "inputs": {
      "image": "temp_1061860375479472201_result_71_0.png.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Upload"
    }
  },
  "82": {
    "inputs": {
      "images": [
        "105",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "85": {
    "inputs": {
      "images": [
        "75",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "86": {
    "inputs": {
      "images": [
        "162",
        0
      ]
    },
    "class_type": "SaveImageWebsocket",
    "_meta": {
      "title": "SaveImageWebsocket"
    }
  },
  "87": {
    "inputs": {
      "text": [
        "56",
        0
      ],
      "clip": [
        "43",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "Positive Prompt"
    }
  },
  "90": {
    "inputs": {
      "guidance": 3.5,
      "conditioning": [
        "87",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "92": {
    "inputs": {
      "text": "",
      "clip": [
        "43",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "Negative Prompt"
    }
  },
  "95": {
    "inputs": {
      "value": "11.txt"
    },
    "class_type": "easy string",
    "_meta": {
      "title": "Prompt Name"
    }
  },
  "97": {
    "inputs": {
      "root_dir": "output",
      "file": [
        "99",
        0
      ],
      "append": "append",
      "insert": true,
      "text": [
        "56",
        0
      ]
    },
    "class_type": "SaveText|pysssss",
    "_meta": {
      "title": "Save Text 🐍"
    }
  },
  "98": {
    "inputs": {
      "value": "Prompt"
    },
    "class_type": "easy string",
    "_meta": {
      "title": "SubFolder"
    }
  },
  "99": {
    "inputs": {
      "delimiter": "/",
      "string1": [
        "98",
        0
      ],
      "string2": [
        "95",
        0
      ]
    },
    "class_type": "JoinStrings",
    "_meta": {
      "title": "Join Strings"
    }
  },
  "101": {
    "inputs": {
      "anything": [
        "26",
        0
      ]
    },
    "class_type": "easy cleanGpuUsed",
    "_meta": {
      "title": "Clean VRAM Used"
    }
  },
  "104": {
    "inputs": {
      "find": "\\n",
      "replace": " ",
      "text": [
        "77",
        2
      ]
    },
    "class_type": "Text Find and Replace",
    "_meta": {
      "title": "Text Find and Replace"
    }
  },
  "105": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "interpolation": "nearest",
      "method": "keep proportion",
      "condition": "always",
      "multiple_of": 0,
      "image": [
        "47",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "🔧 Image Resize"
    }
  },
  "108": {
    "inputs": {
      "pixels": [
        "105",
        0
      ],
      "vae": [
        "42",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "113": {
    "inputs": {
      "type": "canny/lineart/anime_lineart/mlsd",
      "control_net": [
        "65",
        0
      ]
    },
    "class_type": "SetUnionControlNetType",
    "_meta": {
      "title": "SetUnionControlNetType"
    }
  },
  "115": {
    "inputs": {
      "samples": [
        "120",
        0
      ],
      "vae": [
        "42",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "117": {
    "inputs": {
      "images": [
        "115",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "118": {
    "inputs": {
      "strength": 0.6500000000000001,
      "start_percent": 0,
      "end_percent": 0.6000000000000001,
      "positive": [
        "90",
        0
      ],
      "negative": [
        "92",
        0
      ],
      "control_net": [
        "113",
        0
      ],
      "image": [
        "122",
        0
      ],
      "vae": [
        "42",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "120": {
    "inputs": {
      "seed": 61791261579652,
      "steps": 35,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 0.7500000000000001,
      "model": [
        "54",
        0
      ],
      "positive": [
        "118",
        0
      ],
      "negative": [
        "118",
        1
      ],
      "latent_image": [
        "108",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler-03"
    }
  },
  "121": {
    "inputs": {
      "images": [
        "122",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "122": {
    "inputs": {
      "low_threshold": 0.10000000000000002,
      "high_threshold": 0.30000000000000004,
      "image": [
        "105",
        0
      ]
    },
    "class_type": "Canny",
    "_meta": {
      "title": "Canny"
    }
  },
  "129": {
    "inputs": {
      "pixels": [
        "105",
        0
      ],
      "vae": [
        "42",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "133": {
    "inputs": {
      "type": "canny/lineart/anime_lineart/mlsd",
      "control_net": [
        "65",
        0
      ]
    },
    "class_type": "SetUnionControlNetType",
    "_meta": {
      "title": "SetUnionControlNetType"
    }
  },
  "134": {
    "inputs": {
      "samples": [
        "139",
        0
      ],
      "vae": [
        "42",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "136": {
    "inputs": {
      "images": [
        "134",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "137": {
    "inputs": {
      "strength": 0.5000000000000001,
      "start_percent": 0,
      "end_percent": 0.4000000000000001,
      "positive": [
        "90",
        0
      ],
      "negative": [
        "92",
        0
      ],
      "control_net": [
        "133",
        0
      ],
      "image": [
        "122",
        0
      ],
      "vae": [
        "42",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "139": {
    "inputs": {
      "seed": 907192953520508,
      "steps": 35,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 0.7000000000000002,
      "model": [
        "54",
        0
      ],
      "positive": [
        "137",
        0
      ],
      "negative": [
        "137",
        1
      ],
      "latent_image": [
        "129",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler-02"
    }
  },
  "143": {
    "inputs": {
      "pixels": [
        "105",
        0
      ],
      "vae": [
        "42",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "147": {
    "inputs": {
      "type": "canny/lineart/anime_lineart/mlsd",
      "control_net": [
        "65",
        0
      ]
    },
    "class_type": "SetUnionControlNetType",
    "_meta": {
      "title": "SetUnionControlNetType"
    }
  },
  "148": {
    "inputs": {
      "samples": [
        "153",
        0
      ],
      "vae": [
        "42",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "150": {
    "inputs": {
      "images": [
        "148",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "151": {
    "inputs": {
      "strength": 0.4000000000000001,
      "start_percent": 0,
      "end_percent": 0.4000000000000001,
      "positive": [
        "90",
        0
      ],
      "negative": [
        "92",
        0
      ],
      "control_net": [
        "147",
        0
      ],
      "image": [
        "122",
        0
      ],
      "vae": [
        "42",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "153": {
    "inputs": {
      "seed": 647287121207175,
      "steps": 35,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 0.6500000000000001,
      "model": [
        "54",
        0
      ],
      "positive": [
        "151",
        0
      ],
      "negative": [
        "151",
        1
      ],
      "latent_image": [
        "143",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler-04"
    }
  },
  "158": {
    "inputs": {
      "images": [
        "134",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "159": {
    "inputs": {
      "images": [
        "115",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "160": {
    "inputs": {
      "images": [
        "148",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "162": {
    "inputs": {
      "image1": [
        "75",
        0
      ],
      "image2": [
        "134",
        0
      ],
      "image3": [
        "115",
        0
      ],
      "image4": [
        "148",
        0
      ]
    },
    "class_type": "ImpactMakeImageBatch",
    "_meta": {
      "title": "Make Image Batch"
    }
  }
}